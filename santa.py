# -*- coding: utf-8 -*-
"""Santa.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oDpuhYxw6GhOxVw4T3xFBDjH16T4rcdh
"""

from google.colab import drive
drive.mount('/content/drive')

import os  # OpenCV：讀取圖片
import cv2  # OS：走訪圖片
import numpy as np  # Numpy：矩陣運算
import pandas as pd  # pandas ：混淆矩陣視覺呈現
import tensorflow
import matplotlib.pyplot as plt
from keras.models import Sequential
from sklearn.metrics import confusion_matrix
from tensorflow.python.keras.utils.np_utils import to_categorical  # Keras：建立訓練模型
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout

Trainpath = '/content/drive/MyDrive/is that santa/train'
Testpath = '/content/drive/MyDrive/is that santa/test'
x_Train = []   # 儲存訓練資料集處理後的圖片
y_Train = []   # 儲存訓練資料集處理後的label{0: 'not-a-santa', 1: 'santa'}
x_Test = []    # 儲存測試資料集處理後的圖片
y_Test = []    # 儲存測試資料集處理後的label{0: 'not-a-santa', 1: 'santa'}

label_name = {0: 'not-a-santa', 1: 'santa'}
print("Start data processing . . .")

# 訓練資料集處理
for label, folder in label_name.items():
    # 創建指向訓練集中當前標籤文件夾的路徑
    path = os.path.join(Trainpath, folder)
    # 讀取並調整圖片大小
    for img in os.listdir(path):
        imgtrain = cv2.imread(os.path.join(path, img))
        height, width = imgtrain.shape[:2]   #讀取圖片的長跟寬
        # 調整尺寸並保持長寬比
        if height > width:
            new_height = 256
            new_width = int(width * (256 / height))
        else:
            new_width = 256
            new_height = int(height * (256 / width))
        imgtrain = cv2.resize(imgtrain, (new_width, new_height))
        # 添加邊界使圖片為256x256
        top = (256 - new_height) // 2
        bottom = 256 - new_height - top
        left = (256 - new_width) // 2
        right = 256 - new_width - left
        imgtrain = cv2.copyMakeBorder(imgtrain, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0, 0))
        # 將處理後的圖片及其標籤附加到列表中
        x_Train.append(imgtrain)
        y_Train.append(label)
print("Train data processing completed!")

# 測試資料集處理
for label, folder in label_name.items():
    # 創建指向測試集中當前標籤文件夾的路徑
    path = os.path.join(Testpath, folder)
    # 讀取並調整圖片大小
    for img in os.listdir(path):
        imgtest = cv2.imread(os.path.join(path, img))
        height, width = imgtest.shape[:2]  # 讀取圖片的長跟寬
        # 讀取並調整圖片大小
        if height > width:
            new_height = 256
            new_width = int(width * (256 / height))
        else:
            new_width = 256
            new_height = int(height * (256 / width))
        imgtest = cv2.resize(imgtest, (new_width, new_height))
        # 添加邊界使圖片為256x256
        top = (256 - new_height) // 2
        bottom = 256 - new_height - top
        left = (256 - new_width) // 2
        right = 256 - new_width - left
        # 確保圖片最終的尺寸是 256x256
        # value (0, 0, 0, 0) 的前三個 (0, 0, 0) 表示黑色，而最後一個 0 是表示透明），在這裡設為 0 表示完全不透明
        # cv2.BORDER_CONSTANT:指定使用常數值填充邊界
        imgtest = cv2.copyMakeBorder(imgtest, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0, 0))
        # 將處理後的圖片及其標籤附加到列表中
        x_Test.append(imgtest)
        y_Test.append(label)
print("Test data processing completed!")

# 將列表轉為 NumPy 數列
x_Train_array = np.array(x_Train)
x_Test_array = np.array(x_Test)
y_Train = np.array(y_Train)
y_Test = np.array(y_Test)

# 將影像的特徵值轉換為4維矩陣
# 影像大小為 256x256，通道數為 3（RGB）
x_Train4D = x_Train_array.reshape(x_Train_array.shape[0], 256, 256, 3).astype('float32')
x_Test4D = x_Test_array.reshape(x_Test_array.shape[0], 256, 256, 3).astype('float32')

## 數字影像特徵值標準化
x_Train4D_normalize = x_Train4D / 255
x_Test4D_normalize = x_Test4D / 255

# label(數字的真實的值)以Onehot encoding轉換
y_TrainOneHot = to_categorical(y_Train)
y_TestOneHot = to_categorical(y_Test)

# 建立 Sequential 模型
model = Sequential()

# 添加卷積層和池化層
'''
filiters 建立濾鏡(濾鏡數量，一個濾鏡會產生一個特徵圖)
kernel_size 濾鏡大小，在此設置成5X5
padding=’same’ 卷積運算不改變圖片大小
activation=’relu’ 設定激活函數relu
'''
model.add(Conv2D(filters=16, kernel_size=(5, 5), padding='same', input_shape=(256, 256, 3), activation='relu'))
# 設定池化窗口為2X2
model.add(MaxPooling2D(pool_size=(2, 2)))

# 再設一個池化層filters設36
model.add(Conv2D(filters=36, kernel_size=(5, 5), padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# 加入Droput可避免過擬合overfitting
model.add(Dropout(0.25))
# 使用Flatten()平坦層將資料壓成1維
model.add(Flatten())
# 建立隱藏層
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
# 建立輸出層
model.add(Dense(2, activation='softmax'))

# 模型做總結
model.summary()

# 使用compile來定義損失函數、優化函數及成效衡量指標
# loss用cross entropy(交叉熵)
# optimizer採用梯度下降法採取最常用的演算法adam
# metrics:模型的評估方式選擇以accuracy來評估
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# epochs 代表訓練的週期(將資料訓練過十次
# batch_size 每一批訓練256筆資料
# validation_split=0.2 代表從訓練資料集中取20%來當作驗證資料集
# verbose 訓練日誌顯示模式 1 =進度條

train_history=model.fit(x=x_Train4D_normalize, y=y_TrainOneHot, validation_split=0.2, epochs=10, batch_size=256, verbose=1)

# 用matplotlib.pyplot呈現訓練結果
def show_train_history(train_history, train, validation):
  plt.plot(train_history.history[train])
  plt.plot(train_history.history[validation])
  plt.title('Train History')
  if train == 'accuracy':
    plt.ylabel('acc')
  else :
    plt.ylabel('loss')
  plt.xlabel('Epoch')
  plt.legend(['train', 'validation'], loc='center right')
  plt.show()

# 畫出accuracy的執行結果
show_train_history(train_history, 'accuracy', 'val_accuracy')
# 畫出loss誤差的執行結果
show_train_history(train_history, 'loss', 'val_loss')

# 評估模型準確率：將處理過的測試資料放入model.evaluate()中評估模型準確率
loss, accuracy = model.evaluate(x_Test4D_normalize , y_TestOneHot)
print( "\nLoss: %.2f, Accuracy: %.2f%%" % (loss, accuracy* 100 ))

# 顯示混淆矩陣：顯示測試資料預測結果統計與實際結果統計的差異
# 橫向為預測結果 縱向為實際結果
prediction=np.argmax(model.predict(x_Test4D_normalize), axis=1)
print("Confusion Matrix:")
pd.crosstab(y_Test,prediction,rownames=['label'],colnames=['predict'])